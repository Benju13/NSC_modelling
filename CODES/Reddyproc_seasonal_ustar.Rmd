---
title: "Reddyproc_seasonal"
author: "Benju"
date: "2024-01-22"
output:  rmarkdown::github_document
---
USED FOR CRK 2022, 2023, 2024
Seasonal ustar filtering works better than the reddyproc ustar 
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

This is R scripts taken from Reddyproc and modified by me as required by data 
Start with Reddyproc help 

```{r help ReddyProc}
#help("REddyProc")
```

Packages
```{r Load libraries}

if (!requireNamespace("pacman", quietly = TRUE)) {
  install.packages("pacman")
}
pacman::p_load(ggplot2, readxl, dplyr, measurements, SciViews, googlesheets4, tidyverse, 
               lattice, plotrix, writexl, nlme, car, vegan, ggResidpanel, lme4, 
               moments, gridExtra,REddyProc,bigleaf,remotes,FluxGapsR)

```

PAR conversion to SWIN 
SWIN = PPFD (μmol m⁻² s⁻¹) × 0.219 
Approximate 45% of SWIN is par 
1 W m⁻² of PAR corresponds to approximately 4.57 μmol m⁻² s⁻¹ of PPFD.
Read data and change -9999 to nan
Everytime change data and change ustar 
```{r read data}
yyear <- 2024
sitename <- 'CRK' 
filePath <- sprintf("C:/Benju/Matlab_data_play/SouthernPine_DataAnalysis/Input Data/ReddyProc/Seasonal/%s/rp%s_%d.csv", sitename, sitename, yyear)

# Read the CSV file
EddyData <- read_csv(filePath, show_col_types = FALSE)
EddyData [EddyData == -9999] <- NA
EddyData [EddyData == "NaN"] <- NA
#Convert special table to data.frame 
EddyData <- as.data.frame(EddyData)
sum(is.na(EddyData$NEE))
sum(is.na(EddyData$NEE))

##USing PAR to get Rg values when Rg was missing 
EddyData$Rg <- ifelse(EddyData$Year == 2024 &
                     is.na(EddyData$Rg) &
                     EddyData$DoY > 146,
                     EddyData$PPFD * 0.219 / 0.45,
                     EddyData$Rg)

# Modify QC flag for 2024 Jan-Feb to allow QC 0 and 1
if (yyear == 2024) {
    EddyData$QC_flag <- ifelse(EddyData$DoY >= 1 & EddyData$DoY <= 60 & EddyData$QC_flag == 1,
                               0,  # Change QC=1 to QC=0 for Jan-Feb 2024
                               EddyData$QC_flag)
}
```

```{r replace long run values}
EddyData <- filterLongRuns(EddyData, "NEE")
EddyData <- filterLongRuns(EddyData, "LE")
```

##+++ Add time stamp in POSIX time format
```{r add new time column}
EddyDataWithPosix <- fConvertTimeToPosix(
  EddyData, 'YDH',Year = 'Year',Day = 'DoY', Hour = 'Hour') %>% 
  filterLongRuns("NEE")
```

#+++ Initalize R5 reference class sEddyProc for post-processing of eddy data
#+++ with the variables needed for post-processing later
```{r}
# Create the QF vector to match exact number of rows
if (sitename == 'CRK') {
  EProc <- sEddyProc$new(
   'sitename', EddyDataWithPosix, c('NEE','Rg','Tair','VPD', 'Ustar','LE','Tsoil','SWC_5cm', 'SWC_20cm','QC_flag'))

} else if (sitename == 'NC2') {
  EProc <- sEddyProc$new(
'sitename', EddyDataWithPosix, c('NEE','Rg','Tair','VPD', 'Ustar','LE','Tsoil'))
   

} else if (sitename == 'GA') {
     EProc <- sEddyProc$new(
'sitename', EddyDataWithPosix, c('NEE','Rg','Tair','VPD', 'Ustar','LE','Tsoil'))

} else if (sitename == 'CST') {
    EProc <- sEddyProc$new(
'sitename', EddyDataWithPosix, c('NEE','Rg','Tair','VPD', 'Ustar','LE','Tsoil'))
}

```

A fingerprint-plot of the source half-hourly shows already several gaps. A fingerprint-plot is a color-coded image of the half-hourly fluxes by daytime on the x and and day of the year on the y axis.
```{r}
dir.create("Chapter1_figures", showWarnings = FALSE)
png(paste0("Chapter1_figures/fingerprint_NEE_", yyear, ".png"), 
    width = 1800, height = 1200, res = 150)
EProc$sPlotFingerprintY('NEE', Year = yyear)
dev.off()   
EProc$sPlotFingerprintY('NEE', Year = yyear)
EProc$sPlotFingerprintY('LE', Year = yyear)
```

markdown
![](../Chapter1_figures/fingerprint_NEE_2024.png)

#Estimating ustar threshold based on Papale et al., 2006 
The second step, is the estimation of the distribution of uStar thresholds, to identify periods of low friction velocity (uStar), where NEE is biased low. Discarding periods with low uStar is one of the largest sources of uncertainty in aggregated fluxes. Hence, several quantiles of the distribution of the uncertain uStar threshold are estimated by a bootstrap.


For leap year 

```{r}
# Create the QF vector to match exact number of rows
if (sitename == 'CRK') {

  EProc$sMDSGapFill('NEE', QFVar = 'QC_flag', QFValue = 0)
    grep("NEE_.*_f$", names(EProc$sExportResults()), value = TRUE)
    grep("NEE_.*_fsd$", names(EProc$sExportResults()), value = TRUE)

} else if (sitename == 'NC2') {
    EProc$sMDSGapFill('NEE')
    grep("NEE_.*_f$", names(EProc$sExportResults()), value = TRUE)
    grep("NEE_.*_fsd$", names(EProc$sExportResults()), value = TRUE)

} else if (sitename == 'GA') {
    EProc$sMDSGapFill('NEE')
    grep("NEE_.*_f$", names(EProc$sExportResults()), value = TRUE)
    grep("NEE_.*_fsd$", names(EProc$sExportResults()), value = TRUE)

} else if (sitename == 'CST') {
    EProc$sMDSGapFill('NEE')
    grep("NEE_.*_f$", names(EProc$sExportResults()), value = TRUE)
    grep("NEE_.*_fsd$", names(EProc$sExportResults()), value = TRUE)
}
```

```{r}
#+++ Example plots of filled data to screen or to directory \plots
	EProc$sPlotFingerprintY('NEE_f', Year.i=yyear)
```

Finger of the new variables shows that gap has been filled 
```{r}
png(paste0("Chapter1_figures/fingerprint_NEE_f", yyear, ".png"), 
    width = 1800, height = 1200, res = 150)
EProc$sPlotFingerprintY('NEE_f', Year = yyear)
dev.off()
# EProc$sPlotFingerprintY('LE_f', Year = yyear)
```

markdown

 ## NEE Fingerprint Plot
![](../Chapter1_figures/fingerprint_NEE_f2024.png)

Flux partitioning 

```{r}
if (sitename == 'CRK') {
  EProc$sSetLocationInfo(LatDeg = 31.4629, LongDeg = -95.3415, TimeZoneHour = -6)
} else if (sitename == 'NC2') {
  EProc$sSetLocationInfo(LatDeg = 35.8030, LongDeg = -76.6685, TimeZoneHour = -5)
} else if (sitename == 'GA') {
  EProc$sSetLocationInfo(LatDeg = 	31.2792, LongDeg =  -84.5329, TimeZoneHour = -5)
} else if (sitename == 'CST') {
  EProc$sSetLocationInfo(LatDeg = 	33.0442, LongDeg =  -91.9204, TimeZoneHour = -6)
}

EProc$sMDSGapFill('Tair', FillAll = FALSE,  minNWarnRunLength = NA)     
EProc$sMDSGapFill('VPD', FillAll = FALSE,  minNWarnRunLength = NA)    
EProc$sMDSGapFill('Rg', FillAll = FALSE,  minNWarnRunLength = NA)    
if (sitename == 'CRK') {
EProc$sMDSGapFill('SWC_5cm', FillAll = FALSE,  minNWarnRunLength = NA)    
EProc$sMDSGapFill('SWC_20cm', FillAll = FALSE,  minNWarnRunLength = NA) 
}
EProc$sFillVPDFromDew() # fill longer gaps still present in VPD_f


#EProc$sMRFluxPartition()
# Nightime flux partitioning
if (sitename == 'CRK') {
EProc$sMRFluxPartition(T_ref = 273.15 + 20) # use your site's mean temperature for T_ref
} else if (sitename == 'NC2'){
  EProc$sMRFluxPartition(T_ref = 273.15 + 16)
} else if (sitename == 'GA'){
  EProc$sMRFluxPartition(T_ref = 273.15 + 20)
} else if (sitename == 'GA'){
  EProc$sMRFluxPartition(T_ref = 273.15 + 17)
}
# daytime flux partitioning
EProc$sGLFluxPartition()


```

The results are stored in columns Reco and GPP_f modified by the respective u∗
 threshold suffix.
```{r}
grep("GPP.*_f$|Reco",names(EProc$sExportResults()), value = TRUE)
```
Visualizations of the results by a fingerprint plot gives a compact overview.
```{r}
EProc$sPlotFingerprintY('GPP_f', Year = yyear)
```

Storing the results in text 
Change into NaN for matlab use 

```{r}
FilledEddyData <- EProc$sExportResults()

class(data)
class(FilledEddyData)
CombinedData <- cbind(EddyData, FilledEddyData)

## remove long data gap 
# DoY 268-365, year 2023, and site 'crk'
condition <- CombinedData$DoY >= 268 & 
             CombinedData$DoY <= 365 & 
             yyear == 2023 & 
             sitename == "CRK"

CombinedData$Reco <- ifelse(condition, NA, CombinedData$Reco)
CombinedData$GPP_f <- ifelse(condition, NA, CombinedData$GPP_f)
CombinedData$NEE_f <- ifelse(condition, NA, CombinedData$NEE_f)
CombinedData[is.na(CombinedData)] <- NaN
file_name <- paste0(sitename, '_', yyear, '_rpresult.txt')
full_dir_path <- paste0("C:/Benju/Matlab_data_play/SouthernPine_DataAnalysis/Output Data/Reddyproc/Seasonal/", sitename)
fWriteDataframeToFile(CombinedData, file_name, Dir = full_dir_path)
```

DAILY 

```{r}
daily <- CombinedData %>% group_by(DoY) %>%  summarise(precip = mean(Tair))
```

UNCERTAINITIES ANALYSIS
For results use NEE_U95F
UNCERTAINITIES ANALYSIS
Uncertainity in GPP due to ustar scenarios 
Uncertainities asscoiated with NEE 
This code is from 
https://cran.r-project.org/web/packages/REddyProc/vignettes/aggUncertainty.html
1. Computes residuals between original and gapfilled NEE 
2. Calculate autocorrelation of these resduals to account for the temporal dependence in flux measurement- 
3. Determines the effective number of observations (nEff) that accounts for this autocorrelation:
4. Calculates the uncertainty of the mean NEE using variance propagation that accounts for autocorrelation:
5. Propagates these uncertainties when aggregating from half-hourly to daily or annual values using the principle that random errors are added in quadrature:

```{r}
# Calculate daily uncertainty WITHOUT accounting for autocorrelation
daily_uncertainty <- CombinedData %>%
  group_by(Year, DoY) %>%
  summarise(
    # Count actual measurements per day
    nRec = sum(is.finite(NEE_fsd)),
    # Daily mean NEE
    NEE_daily = mean(NEE_f, na.rm = TRUE),
    # Daily uncertainty using standard error formula
    daily_uncertainty = sqrt(mean(NEE_fsd^2, na.rm = TRUE) / (nRec - 1)),
    .groups = 'drop'
  )

# Aggregate to annual level WITHOUT accounting for autocorrelation
annual_uncertainty <- daily_uncertainty %>%
  group_by(Year) %>%
  summarise(
    # Annual mean NEE
    NEE_annual = mean(NEE_daily, na.rm = TRUE),
    # Count days with data
    n_days = sum(!is.na(daily_uncertainty)),
    # Annual uncertainty - average daily uncertainty divided by sqrt(n_days)
    annual_uncertainty = mean(daily_uncertainty, na.rm = TRUE) / sqrt(n_days),
    # Convert to g C/m²/year
    multiplier = 12 * 10^(-6) * 60 * 60 * 24 * 365,
    NEE_annual_gC = NEE_annual * multiplier,
    annual_uncertainty_gC = annual_uncertainty * multiplier,
    .groups = 'drop'
  )

print(annual_uncertainty)
```

For 2023 annual uncertainity is 10 for 9 months
including 12 months, uncertainity is 

Account fot autoorrelation
```{r}
library(dplyr)
library(forecast)  # For acf() function

# Step 1: Calculate daily uncertainty WITH autocorrelation
daily_uncertainty <- CombinedData %>%
  group_by(Year, DoY) %>%
  summarise(
    # Count actual measurements per day
    nRec = sum(is.finite(NEE_fsd)),
    # Daily mean NEE
    NEE_daily = mean(NEE_f, na.rm = TRUE),
    # Daily uncertainty using standard error formula
    daily_uncertainty = sqrt(mean(NEE_fsd^2, na.rm = TRUE) / (nRec - 1)),
    .groups = 'drop'
  )

# Step 2: Calculate autocorrelation and effective sample size
# Combine all daily NEE data into a single time series
nee_time_series <- CombinedData$NEE_f[is.finite(CombinedData$NEE_f)]

# Compute autocorrelation function (ACF)
acf_result <- acf(nee_time_series, plot = FALSE, lag.max = 100)

# Find the lag where autocorrelation drops to near zero
lag_zero <- which(acf_result$acf < 0.05)[1]  # First lag where ACF < 0.05

# Calculate effective sample size (N_eff)
N_total <- length(nee_time_series)  # Total number of observations
N_eff <- N_total / lag_zero  # Effective sample size

# Step 3: Adjust daily uncertainty for autocorrelation
daily_uncertainty <- daily_uncertainty %>%
  mutate(
    daily_uncertainty_autocorr = daily_uncertainty * sqrt(lag_zero)
  )

# Step 4: Aggregate to annual level WITH autocorrelation
annual_uncertainty <- daily_uncertainty %>%
  group_by(Year) %>%
  summarise(
    # Annual mean NEE
    NEE_annual = mean(NEE_daily, na.rm = TRUE),
    # Count days with data
    n_days = sum(!is.na(daily_uncertainty_autocorr)),
    # Annual uncertainty - average daily uncertainty divided by sqrt(n_days)
    annual_uncertainty = mean(daily_uncertainty_autocorr, na.rm = TRUE) / sqrt(n_days),
    # Convert to g C/m²/year
    multiplier = 12 * 10^(-6) * 60 * 60 * 24 * 365,
    NEE_annual_gC = NEE_annual * multiplier,
    annual_uncertainty_gC = annual_uncertainty * multiplier,
    .groups = 'drop'
  )

print(annual_uncertainty)
```

## Gapfilling uncertainity 

```{r}
# Check ALL uncertainty-related columns
uncertainty_cols <- grep("_fsd|_fqc|uncertainty|sd", names(EProc$sExportResults()), 
                         value = TRUE, ignore.case = TRUE)
print("Available uncertainty columns:")
print(uncertainty_cols)

# Specifically check for GPP and Reco uncertainties
flux_uncertainties <- grep("GPP.*_fsd|Reco.*_fsd|GPP.*uncertainty|Reco.*uncertainty", 
                          names(EProc$sExportResults()), value = TRUE, ignore.case = TRUE)
print("GPP/Reco uncertainty columns:")
print(flux_uncertainties)
```



CHECK

```{r}
# Plot original NEE vs gap-filled NE
# Check what NEE columns we have
nee_cols <- grep("NEE", names(CombinedData), value = TRUE)
print("Available NEE columns:")
print(nee_cols)

# Create comparison plot
if("NEE" %in% names(CombinedData) && "NEE_f" %in% names(CombinedData)) {
  
  # Create a data frame for plotting
  plot_data <- data.frame(
    DoY = CombinedData$DoY,
    NEE_orig = CombinedData$NEE,        # Original NEE
    NEE_filled = CombinedData$NEE_f,    # Gap-filled NEE
    Year = CombinedData$Year
  )
  
  # Time series plot
  p1 <- ggplot(plot_data, aes(x = DoY)) +
    geom_point(aes(y = NEE_orig, color = "Original"), alpha = 0.6, size = 0.8) +
    geom_point(aes(y = NEE_filled, color = "Gap-filled"), alpha = 0.6, size = 0.8) +
    scale_color_manual(values = c("Original" = "blue", "Gap-filled" = "red")) +
    labs(x = "Day of Year", 
         y = "NEE (μmol CO₂ m⁻² s⁻¹)",
         title = paste("Original vs Gap-filled NEE -", yyear),
         color = "Data Type") +
    theme_minimal() +
    facet_wrap(~Year)
  
  print(p1)
  
  # Scatter plot comparison
  p2 <- ggplot(plot_data, aes(x = NEE_orig, y = NEE_filled)) +
    geom_point(alpha = 0.5) +
    geom_abline(slope = 1, intercept = 0, color = "red", linetype = "dashed") +
    labs(x = "Original NEE", 
         y = "Gap-filled NEE",
         title = "Original vs Gap-filled NEE Scatter Plot") +
    theme_minimal()
  
  print(p2)
  
  # Print summary statistics
  cat("\nSummary comparison:\n")
  cat("Original NEE - Mean:", mean(plot_data$NEE_orig, na.rm = TRUE), "\n")
  cat("Gap-filled NEE - Mean:", mean(plot_data$NEE_filled, na.rm = TRUE), "\n")
  cat("Number of original measurements:", sum(!is.nan(plot_data$NEE_orig)), "\n")
  cat("Number of gap-filled values:", sum(!is.nan(plot_data$NEE_filled)), "\n")
  
} else {
  print("Could not find both NEE and NEE_f columns for comparison")
  print("Available columns:")
  print(names(CombinedData)[grep("NEE", names(CombinedData))])
}

# Check if original data was preserved
if("NEE" %in% names(EddyData) && "NEE" %in% names(CombinedData)) {
  original_preserved <- identical(EddyData$NEE, CombinedData$NEE)
  cat("\nOriginal NEE data preserved:", original_preserved, "\n")
} else {
  cat("\nCannot verify if original NEE was preserved - column missing\n")
}
```

```{r}
ggplot(data =CombinedData)+
  geom_point(aes(x= Tair, y =Reco ))
```

